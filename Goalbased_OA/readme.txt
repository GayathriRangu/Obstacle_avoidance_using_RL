TASK: To make the e-puck perform obstacle avoidance, along with the goal of moving to a fixed target/ goal location from any starting point within the arena. The first algorithm is a straightforward implementation without any learning, just using the hardcoded logic for OA and goal reach. The second controller is an implementation of a DQN-based learning algorithm for the given task. This has other components which are not specific to this project, require some cleaning. As this was a modular code of one of my research projects, this code is exhaustive with other additional components, and is not optimal in any way, hence please go through it at your own risk :>
